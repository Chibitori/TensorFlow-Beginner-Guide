{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF DF with Data Variations - Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnnJmuUnNuFZBaNNKQWKBD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikmswamy/TF_Intro_Notebooks/blob/master/TF_DF_with_Data_Variations_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xrI9mMFGAK"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u1n95o8f1Sz"
      },
      "source": [
        "# !pip install -U augly\n",
        "# !sudo apt-get install python3-magic\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZjEjvCeFJtI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWIfTG5Mgok3"
      },
      "source": [
        "from time import time\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av22s03cFNMg"
      },
      "source": [
        "## Data Download and Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "ORMNK-GRvs1N",
        "outputId": "cc8ac230-f89f-45d0-f258-e2a33954d14f"
      },
      "source": [
        "! wget -O bestBuy.csv \"https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\"\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"./bestBuy.csv\", usecols=['manufacturer', 'price', 'description'])\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-04 11:33:17--  https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9921374 (9.5M) [text/plain]\n",
            "Saving to: ‘bestBuy.csv’\n",
            "\n",
            "\rbestBuy.csv           0%[                    ]       0  --.-KB/s               \rbestBuy.csv         100%[===================>]   9.46M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-08-04 11:33:17 (78.4 MB/s) - ‘bestBuy.csv’ saved [9921374/9921374]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Compatible with select electronic devices; AAA...</td>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Long-lasting energy; DURALOCK Power Preserve t...</td>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Compatible with select electronic devices; AA ...</td>\n",
              "      <td>Duracell</td>\n",
              "      <td>7.49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description manufacturer  price\n",
              "0  Compatible with select electronic devices; AAA...     Duracell   5.49\n",
              "1  Long-lasting energy; DURALOCK Power Preserve t...     Duracell   5.49\n",
              "2  Compatible with select electronic devices; AA ...     Duracell   7.49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBkfGBICQlA",
        "outputId": "3af41734-f403-4dba-fe70-abac4a36d185"
      },
      "source": [
        "dataset_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48087 entries, 0 to 48086\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   description   48087 non-null  object \n",
            " 1   manufacturer  48023 non-null  object \n",
            " 2   price         48087 non-null  float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AckVwakyK2w"
      },
      "source": [
        "# Name of the label column.\n",
        "label = \"price\"\n",
        "\n",
        "# classes = dataset_df[label].unique().tolist()\n",
        "# print(f\"Label classes: {classes}\")\n",
        "\n",
        "# dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csVpYLqVFSbI"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0guQ8ZfPyUGp"
      },
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "# Test split remains a constant \n",
        "def split_dataset(dataset, num_train=10000):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  dataset = dataset.sample(frac=1.0, random_state=1729)\n",
        "  \n",
        "  test_dataset = dataset[40000:]\n",
        "  train_dataset = dataset[:num_train]\n",
        "  \n",
        "  return train_dataset, test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhY2Dcoopv6V"
      },
      "source": [
        "def train_rf_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, \n",
        "                                                     label=label, \n",
        "                                                     task=tfdf.keras.Task.REGRESSION)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, \n",
        "                                                    label=label, \n",
        "                                                    task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.RandomForestModel(num_trees=30, task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"mse\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "    print(f\"MSE: {evaluation['mse']} in {time() - t1} secs\")\n",
        "    return evaluation['mse'], time() - t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KWdeFTmwXlu"
      },
      "source": [
        "def train_gbdt_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, \n",
        "                                                     label=label, \n",
        "                                                     task=tfdf.keras.Task.REGRESSION)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, \n",
        "                                                    label=label, \n",
        "                                                    task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.GradientBoostedTreesModel(num_trees=30,\n",
        "                                                   task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"mse\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "    print(f\"MSE: {evaluation['mse']} in {time() - t1} secs\")\n",
        "    return evaluation['mse'], time() - t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPDKs0dWMEKU"
      },
      "source": [
        "def train_cart_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, \n",
        "                                                     label=label, \n",
        "                                                     task=tfdf.keras.Task.REGRESSION)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, \n",
        "                                                    label=label, \n",
        "                                                    task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.CartModel(task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"mse\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "    print(f\"MSE: {evaluation['mse']} in {time() - t1} secs\")\n",
        "    return evaluation['mse'], time() - t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQjlNHKFayw"
      },
      "source": [
        "## Train with Different Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiNb6QjF30m"
      },
      "source": [
        "def train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm):\n",
        "    train_ds_pd, test_ds_pd = split_dataset(dataset_df, num_train)\n",
        "    print(f\"{len(train_ds_pd)} examples in training, {len(test_ds_pd)} examples for testing.\")\n",
        "\n",
        "    accuracy, time_taken = train_rf_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_rf.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_gbdt_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_gb.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_cart_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_cm.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    return results_rf, results_gb, results_cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSg1c2rUWv2_",
        "outputId": "db1caf20-9f29-4e21-fedb-1a012b21c073"
      },
      "source": [
        "results_rf, results_gb, results_cm = [], [], []\n",
        "num_train_list = [500, 1000, 2000, 4000, 8000, 16000, 32000, 40000]\n",
        "for num_train in num_train_list:\n",
        "    results_rf, results_gb, results_cm = train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 examples in training, 8087 examples for testing.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-04 11:33:22.652240: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-08-04 11:33:22.654482: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 4s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 492 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:1 num-oods:492 (98.4%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 500 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done rmse:399.224\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:13) done rmse:709.933\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:21) done rmse:703.777\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:20) done rmse:701.816\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:701.816\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp2_t2kv0b\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 700 node(s), and 1 input feature(s).\n",
            "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 269679.3438\n",
            "MSE: 269679.34375 in 7.440796613693237 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 492 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:1 num-oods:492 (98.4%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 500 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:735.859619 train-rmse:735.859619 valid-loss:319.397186 valid-rmse:319.397186\n",
            "[INFO gradient_boosted_trees.cc:1495] \tnum-trees:2 train-loss:733.001221 train-rmse:733.001221 valid-loss:312.392151 valid-rmse:312.392151\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:720.710938 train-rmse:720.710938 valid-loss:269.046722 valid-rmse:269.046722\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:269.046722 valid-rmse:269.046722\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpxu5x609p\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 272940.0938\n",
            "MSE: 272940.09375 in 0.6914722919464111 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 492 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:1 num-oods:492 (98.4%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 500 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 27 nodes before pruning. 1 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpoj4f8njm\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 293103.0938\n",
            "MSE: 293103.09375 in 0.4357109069824219 secs\n",
            "1000 examples in training, 8087 examples for testing.\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 981 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:2 num-oods:981 (98.1%) most-frequent:\"<OOD>\" 981 (98.1%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 1000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:1) done rmse:527.934\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:12) done rmse:647.502\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:23) done rmse:644.797\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:18) done rmse:647.94\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:647.94\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpln4v2msv\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 1904 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 246594.3750\n",
            "MSE: 246594.375 in 0.6491308212280273 secs\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 981 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:2 num-oods:981 (98.1%) most-frequent:\"<OOD>\" 981 (98.1%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 1000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:675.225586 train-rmse:675.225586 valid-loss:281.195618 valid-rmse:281.195618\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:646.013855 train-rmse:646.013855 valid-loss:303.341827 valid-rmse:303.341827\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 5 tree(s) i.e. 5  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:5 valid-loss:268.348907 valid-rmse:268.348907\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpbbmt88_j\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7ffa2f899560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7ffa2f899560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 262392.1875\n",
            "MSE: 262392.1875 in 0.6935760974884033 secs\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 981 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:2 num-oods:981 (98.1%) most-frequent:\"<OOD>\" 981 (98.1%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 1000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 67 nodes before pruning. 1 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpp42w4q3m\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7ffa2f82acb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7ffa2f82acb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 293418.6875\n",
            "MSE: 293418.6875 in 0.7029500007629395 secs\n",
            "2000 examples in training, 8087 examples for testing.\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 1939 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:2 num-oods:1939 (96.95%) most-frequent:\"<OOD>\" 1939 (96.95%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 2000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:2) done rmse:686.686\n",
            "[INFO random_forest.cc:578] Training of tree  12/30 (tree index:13) done rmse:586.39\n",
            "[INFO random_forest.cc:578] Training of tree  22/30 (tree index:23) done rmse:583.775\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:26) done rmse:583.444\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:583.444\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpbg0wkmha\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 4442 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 216878.3750\n",
            "MSE: 216878.375 in 0.8594691753387451 secs\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 1939 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:2 num-oods:1939 (96.95%) most-frequent:\"<OOD>\" 1939 (96.95%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 2000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:626.446289 train-rmse:626.446289 valid-loss:605.039307 valid-rmse:605.039307\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:551.758057 train-rmse:551.758057 valid-loss:509.166718 valid-rmse:509.166718\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:509.166718 valid-rmse:509.166718\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpdmz7vqi7\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 221099.3438\n",
            "MSE: 221099.34375 in 0.6145169734954834 secs\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 1939 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:2 num-oods:1939 (96.95%) most-frequent:\"<OOD>\" 1939 (96.95%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 2000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 163 nodes before pruning. 1 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpht0giwje\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 292985.5625\n",
            "MSE: 292985.5625 in 0.5443425178527832 secs\n",
            "4000 examples in training, 8087 examples for testing.\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 3794 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (2 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:3 num-oods:3794 (94.85%) most-frequent:\"<OOD>\" 3794 (94.85%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 4000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done rmse:465.556\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:7) done rmse:540.001\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:24) done rmse:539.581\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done rmse:540.388\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:540.388\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp302f7u10\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 10768 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 210317.1719\n",
            "MSE: 210317.171875 in 1.1597154140472412 secs\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 3794 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (2 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:3 num-oods:3794 (94.85%) most-frequent:\"<OOD>\" 3794 (94.85%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 4000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:609.133850 train-rmse:609.133850 valid-loss:626.224060 valid-rmse:626.224060\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:510.584808 train-rmse:510.584808 valid-loss:562.862305 valid-rmse:562.862305\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 23 tree(s) i.e. 23  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:23 valid-loss:562.458862 valid-rmse:562.458862\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpifojjhmy\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 210001.8438\n",
            "MSE: 210001.84375 in 0.8527331352233887 secs\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 3794 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (2 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:3 num-oods:3794 (94.85%) most-frequent:\"<OOD>\" 3794 (94.85%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 4000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 381 nodes before pruning. 29 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp9givjfsc\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 29 node(s), and 1 input feature(s).\n",
            "[INFO abstract_model.cc:993] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 214235.8281\n",
            "MSE: 214235.828125 in 0.5350396633148193 secs\n",
            "8000 examples in training, 8087 examples for testing.\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 7299 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (11 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:12 num-oods:7299 (91.2375%) most-frequent:\"<OOD>\" 7299 (91.2375%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 8000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:5) done rmse:465.48\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done rmse:473.125\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done rmse:471.292\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:27) done rmse:471.573\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:471.573\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp1n3g0_v7\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 16706 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 194922.5469\n",
            "MSE: 194922.546875 in 5.648832082748413 secs\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 7299 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (11 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:12 num-oods:7299 (91.2375%) most-frequent:\"<OOD>\" 7299 (91.2375%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 8000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:571.475281 train-rmse:571.475281 valid-loss:659.861694 valid-rmse:659.861694\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:465.522125 train-rmse:465.522125 valid-loss:572.927124 valid-rmse:572.927124\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:572.927124 valid-rmse:572.927124\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp68u7pdcf\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO abstract_model.cc:993] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 197832.9531\n",
            "MSE: 197832.953125 in 5.670016288757324 secs\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 7299 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (11 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:12 num-oods:7299 (91.2375%) most-frequent:\"<OOD>\" 7299 (91.2375%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 8000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 565 nodes before pruning. 3 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpqm79mles\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 3 node(s), and 1 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 278359.1875\n",
            "MSE: 278359.1875 in 1.0239930152893066 secs\n",
            "16000 examples in training, 8087 examples for testing.\n",
            "250/250 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 13722 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (61 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:62 num-oods:13722 (85.7625%) most-frequent:\"<OOD>\" 13722 (85.7625%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 16000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:2) done rmse:543.983\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done rmse:477.093\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done rmse:472.478\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done rmse:472.245\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:472.245\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp5n7s_bhc\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 29762 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 194923.3281\n",
            "MSE: 194923.328125 in 10.71260404586792 secs\n",
            "250/250 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 13722 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (61 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:62 num-oods:13722 (85.7625%) most-frequent:\"<OOD>\" 13722 (85.7625%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 16000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:578.071045 train-rmse:578.071045 valid-loss:655.776062 valid-rmse:655.776062\n",
            "[INFO gradient_boosted_trees.cc:1495] \tnum-trees:2 train-loss:566.903992 train-rmse:566.903992 valid-loss:645.946960 valid-rmse:645.946960\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:482.657745 train-rmse:482.657745 valid-loss:577.346313 valid-rmse:577.346313\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:577.346313 valid-rmse:577.346313\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp7869mw7z\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO abstract_model.cc:993] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 203034.9062\n",
            "MSE: 203034.90625 in 9.510514974594116 secs\n",
            "250/250 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 13722 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (61 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:62 num-oods:13722 (85.7625%) most-frequent:\"<OOD>\" 13722 (85.7625%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 16000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 1019 nodes before pruning. 3 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpiixmhvpk\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 3 node(s), and 1 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 285371.5625\n",
            "MSE: 285371.5625 in 1.0477869510650635 secs\n",
            "32000 examples in training, 8087 examples for testing.\n",
            "500/500 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 25128 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (294 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:295 num-oods:25128 (78.525%) most-frequent:\"<OOD>\" 25128 (78.525%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 32000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:1) done rmse:449.718\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:11) done rmse:454.76\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:21) done rmse:452.649\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:28) done rmse:452.683\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:452.683\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp7z4vbgqe\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 53352 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:993] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 185003.6719\n",
            "MSE: 185003.671875 in 20.975285291671753 secs\n",
            "500/500 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 25128 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (294 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:295 num-oods:25128 (78.525%) most-frequent:\"<OOD>\" 25128 (78.525%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 32000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:571.748047 train-rmse:571.748047 valid-loss:594.533386 valid-rmse:594.533386\n",
            "[INFO gradient_boosted_trees.cc:1495] \tnum-trees:2 train-loss:566.121338 train-rmse:566.121338 valid-loss:587.819763 valid-rmse:587.819763\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:480.651154 train-rmse:480.651154 valid-loss:499.694153 valid-rmse:499.694153\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:499.694153 valid-rmse:499.694153\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp3d1gj8w6\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO abstract_model.cc:993] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 206332.9062\n",
            "MSE: 206332.90625 in 20.87785816192627 secs\n",
            "500/500 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 25128 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (294 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:295 num-oods:25128 (78.525%) most-frequent:\"<OOD>\" 25128 (78.525%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 32000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 1869 nodes before pruning. 69 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp9jfga24i\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 69 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 244542.8750\n",
            "MSE: 244542.875 in 1.7767224311828613 secs\n",
            "40000 examples in training, 8087 examples for testing.\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 30261 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (452 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:453 num-oods:30261 (75.6525%) most-frequent:\"<OOD>\" 30261 (75.6525%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 40000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done rmse:394.024\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:11) done rmse:467.658\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done rmse:465.731\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done rmse:465.263\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:465.263\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp3hi09gao\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 62512 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:993] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 182668.6875\n",
            "MSE: 182668.6875 in 17.76349449157715 secs\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 30261 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (452 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:453 num-oods:30261 (75.6525%) most-frequent:\"<OOD>\" 30261 (75.6525%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 40000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:585.013123 train-rmse:585.013123 valid-loss:564.907166 valid-rmse:564.907166\n",
            "[INFO gradient_boosted_trees.cc:1495] \tnum-trees:2 train-loss:582.239136 train-rmse:582.239136 valid-loss:561.454651 valid-rmse:561.454651\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:500.545959 train-rmse:500.545959 valid-loss:472.071045 valid-rmse:472.071045\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:472.071045 valid-rmse:472.071045\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpvcncv8gp\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO abstract_model.cc:993] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 207526.9375\n",
            "MSE: 207526.9375 in 21.043383836746216 secs\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 30261 item(s) have been pruned (i.e. they are considered out of dictionary) for the column description (452 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"description\" CATEGORICAL has-dict vocab-size:453 num-oods:30261 (75.6525%) most-frequent:\"<OOD>\" 30261 (75.6525%)\n",
            "\t1: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t2: \"__LABEL\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"description\"\n",
            "features: \"manufacturer\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 40000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:371] 2159 nodes before pruning. 69 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmps7inzj6k\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 69 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 261204.6719\n",
            "MSE: 261204.671875 in 2.105123996734619 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-XEOe1vFn6Z"
      },
      "source": [
        "## Plotting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "I6e-QbOzI1oN",
        "outputId": "e3b9e096-c768-4adc-c1b6-06c189d1e438"
      },
      "source": [
        "x  = [res[0] for res in results_rf]\n",
        "y1 = [res[1] for res in results_rf]\n",
        "y2 = [res[1] for res in results_gb]\n",
        "y3 = [res[1] for res in results_cm]\n",
        "plt.plot(x, y1, label=\"Random Forests\", marker='^')\n",
        "plt.plot(x, y2, label=\"Gradient Boosting\", marker='o')\n",
        "plt.plot(x, y3, label=\"CART\", marker='o')\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Number of Records\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Plot of # of Records vs. Accuracies\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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