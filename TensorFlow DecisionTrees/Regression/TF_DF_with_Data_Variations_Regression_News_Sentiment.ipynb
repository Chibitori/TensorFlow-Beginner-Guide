
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF DF with Data Variations - Regression: News Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwACelbvbrxmqq4zM5UcKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikmswamy/TF_Intro_Notebooks/blob/master/TF_DF_with_Data_Variations_Regression_News_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xrI9mMFGAK"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u1n95o8f1Sz"
      },
      "source": [
        "# !pip install -U augly\n",
        "# !sudo apt-get install python3-magic\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZjEjvCeFJtI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWIfTG5Mgok3"
      },
      "source": [
        "from time import time\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av22s03cFNMg"
      },
      "source": [
        "## Data Download and Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUZnURHPDu5V",
        "outputId": "6dce18b8-6d75-4738-adb2-f3825f11bbae"
      },
      "source": [
        "!unzip train_news_sentiment.csv.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train_news_sentiment.csv.zip\n",
            "  inflating: train_news_sentiment.csv  \n",
            "  inflating: __MACOSX/._train_news_sentiment.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "ORMNK-GRvs1N",
        "outputId": "9717ae1d-b397-4b99-c827-7d6977023475"
      },
      "source": [
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"./train_news_sentiment.csv\", usecols=[\"Headline\", \"SentimentHeadline\"])\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
              "      <td>-0.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tim Haywood, investment director business-unit...</td>\n",
              "      <td>-0.156386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
              "      <td>0.139754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  SentimentHeadline\n",
              "0  Obama Lays Wreath at Arlington National Cemete...          -0.053300\n",
              "1  Tim Haywood, investment director business-unit...          -0.156386\n",
              "2  Nouriel Roubini, NYU professor and chairman at...           0.139754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBkfGBICQlA",
        "outputId": "7c336cb7-40ba-4589-a841-9589947977b2"
      },
      "source": [
        "dataset_df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 93239 entries, 0 to 93238\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Headline           93224 non-null  object \n",
            " 1   SentimentHeadline  93239 non-null  float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AckVwakyK2w"
      },
      "source": [
        "# Name of the label column.\n",
        "label = \"SentimentHeadline\"\n",
        "\n",
        "# classes = dataset_df[label].unique().tolist()\n",
        "# print(f\"Label classes: {classes}\")\n",
        "\n",
        "# dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DekImR8i_TlS",
        "outputId": "f2fcbb4b-5e9f-4ef0-b53c-42e6696d6eb3"
      },
      "source": [
        "print(f\"Number of records in dataframe: {len(dataset_df)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of records in dataframe: 93239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csVpYLqVFSbI"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0guQ8ZfPyUGp"
      },
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "# Test split remains a constant \n",
        "def split_dataset(dataset, num_train=10000):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  dataset = dataset.sample(frac=1.0, random_state=1729)\n",
        "  \n",
        "  test_dataset = dataset[90000:]\n",
        "  train_dataset = dataset[:num_train]\n",
        "  \n",
        "  return train_dataset, test_dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhY2Dcoopv6V"
      },
      "source": [
        "def train_rf_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, \n",
        "                                                     label=label, \n",
        "                                                     task=tfdf.keras.Task.REGRESSION)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, \n",
        "                                                    label=label, \n",
        "                                                    task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.RandomForestModel(num_trees=30, task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"mse\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "    print(f\"MSE: {evaluation['mse']} in {time() - t1} secs\")\n",
        "    return evaluation['mse'], time() - t1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KWdeFTmwXlu"
      },
      "source": [
        "def train_gbdt_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, \n",
        "                                                     label=label, \n",
        "                                                     task=tfdf.keras.Task.REGRESSION)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, \n",
        "                                                    label=label, \n",
        "                                                    task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.GradientBoostedTreesModel(num_trees=30,\n",
        "                                                   task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"mse\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "    print(f\"MSE: {evaluation['mse']} in {time() - t1} secs\")\n",
        "    return evaluation['mse'], time() - t1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPDKs0dWMEKU"
      },
      "source": [
        "def train_cart_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, \n",
        "                                                     label=label, \n",
        "                                                     task=tfdf.keras.Task.REGRESSION)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, \n",
        "                                                    label=label, \n",
        "                                                    task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.CartModel(task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"mse\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "\n",
        "    print(f\"MSE: {evaluation['mse']} in {time() - t1} secs\")\n",
        "    return evaluation['mse'], time() - t1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQjlNHKFayw"
      },
      "source": [
        "## Train with Different Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiNb6QjF30m"
      },
      "source": [
        "def train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm):\n",
        "    train_ds_pd, test_ds_pd = split_dataset(dataset_df, num_train)\n",
        "    print(f\"{len(train_ds_pd)} examples in training, {len(test_ds_pd)} examples for testing.\")\n",
        "\n",
        "    accuracy, time_taken = train_rf_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_rf.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_gbdt_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_gb.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_cart_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_cm.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    return results_rf, results_gb, results_cm"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSg1c2rUWv2_",
        "outputId": "2618c7dc-fdcb-4e30-b3ae-77d2b42c5519"
      },
      "source": [
        "results_rf, results_gb, results_cm = [], [], []\n",
        "num_train_list = [500, 1000, 5000, 10000, 30000, 50000, 70000, 90000]\n",
        "for num_train in num_train_list:\n",
        "    results_rf, results_gb, results_cm = train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 examples in training, 3239 examples for testing.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-04 12:08:45.105294: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-08-04 12:08:45.108505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1999995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 4s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 500 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL has-dict vocab-size:1 num-oods:500 (100%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0276183 min:-0.616233 max:0.463713 sd:0.144971\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 500 example(s) and 1 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done rmse:0.132768\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done rmse:0.145676\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:21) done rmse:0.145544\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:23) done rmse:0.145498\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:0.145498\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpgwk9dbij\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 30 node(s), and 0 input feature(s).\n",
            "[INFO abstract_model.cc:993] Engine \"RandomForestOptPred\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.01992115005850792 in 7.066693305969238 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 500 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL has-dict vocab-size:1 num-oods:500 (100%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0276183 min:-0.616233 max:0.463713 sd:0.144971\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 500 example(s) and 1 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:0.145560 train-rmse:0.145560 valid-loss:0.139077 valid-rmse:0.139077\n",
            "[INFO gradient_boosted_trees.cc:1495] \tnum-trees:2 train-loss:0.145560 train-rmse:0.145560 valid-loss:0.139077 valid-rmse:0.139077\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:0.145560 train-rmse:0.145560 valid-loss:0.139077 valid-rmse:0.139077\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 1 tree(s) i.e. 1  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:1 valid-loss:0.139077 valid-rmse:0.139077\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp00zo_t07\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019917961210012436 in 0.3465244770050049 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 500 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL has-dict vocab-size:1 num-oods:500 (100%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0276183 min:-0.616233 max:0.463713 sd:0.144971\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 500 example(s) and 1 feature(s).\n",
            "[INFO cart.cc:371] 1 nodes before pruning. 1 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp7m_hzi5m\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019917961210012436 in 0.3907508850097656 secs\n",
            "1000 examples in training, 3239 examples for testing.\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 999 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL has-dict vocab-size:1 num-oods:999 (99.9%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0265869 min:-0.616233 max:0.596004 sd:0.144593\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 1000 example(s) and 1 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done rmse:0.135452\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:9) done rmse:0.144835\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:21) done rmse:0.144744\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done rmse:0.144822\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:0.144822\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp5r5szkah\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 30 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019918102771043777 in 0.5160074234008789 secs\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 999 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL has-dict vocab-size:1 num-oods:999 (99.9%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0265869 min:-0.616233 max:0.596004 sd:0.144593\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 1000 example(s) and 1 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:0.144928 train-rmse:0.144928 valid-loss:0.140549 valid-rmse:0.140549\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:0.144928 train-rmse:0.144928 valid-loss:0.140549 valid-rmse:0.140549\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 1 tree(s) i.e. 1  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:1 valid-loss:0.140549 valid-rmse:0.140549\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpclw5022b\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f11ac36f7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f11ac36f7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019918406382203102 in 0.508671760559082 secs\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 999 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL has-dict vocab-size:1 num-oods:999 (99.9%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0265869 min:-0.616233 max:0.596004 sd:0.144593\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 1000 example(s) and 1 feature(s).\n",
            "[INFO cart.cc:371] 1 nodes before pruning. 1 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpgj4ymuuk\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f11ac4a9830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f11ac4a9830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019918406382203102 in 0.4243648052215576 secs\n",
            "5000 examples in training, 3239 examples for testing.\n",
            "79/79 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 79\n",
            "[INFO kernel.cc:393] Number of examples: 5000\n",
            "[INFO data_spec_inference.cc:289] 4976 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 5000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:1 (0.02%) has-dict vocab-size:1 num-oods:4976 (99.5399%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0291007 min:-0.616233 max:0.964646 sd:0.14287\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 5000 example(s) and 1 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done rmse:0.137464\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:13) done rmse:0.14278\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:23) done rmse:0.142918\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:17) done rmse:0.142905\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:0.142905\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpwmpqtadn\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 30 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019924994558095932 in 0.6668391227722168 secs\n",
            "79/79 [==============================] - 0s 986us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 79\n",
            "[INFO kernel.cc:393] Number of examples: 5000\n",
            "[INFO data_spec_inference.cc:289] 4976 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 5000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:1 (0.02%) has-dict vocab-size:1 num-oods:4976 (99.5399%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0291007 min:-0.616233 max:0.964646 sd:0.14287\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 5000 example(s) and 1 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:0.143064 train-rmse:0.143064 valid-loss:0.141071 valid-rmse:0.141071\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:0.143064 train-rmse:0.143064 valid-loss:0.141071 valid-rmse:0.141071\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 1 tree(s) i.e. 1  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:1 valid-loss:0.141071 valid-rmse:0.141071\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpgqnfi2rp\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.01992759481072426 in 0.5423855781555176 secs\n",
            "79/79 [==============================] - 0s 976us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 79\n",
            "[INFO kernel.cc:393] Number of examples: 5000\n",
            "[INFO data_spec_inference.cc:289] 4976 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 5000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:1 (0.02%) has-dict vocab-size:1 num-oods:4976 (99.5399%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0291007 min:-0.616233 max:0.964646 sd:0.14287\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 5000 example(s) and 1 feature(s).\n",
            "[INFO cart.cc:371] 1 nodes before pruning. 1 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp4b5phub4\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.01992759481072426 in 0.5177645683288574 secs\n",
            "10000 examples in training, 3239 examples for testing.\n",
            "157/157 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 157\n",
            "[INFO kernel.cc:393] Number of examples: 10000\n",
            "[INFO data_spec_inference.cc:289] 9894 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 10000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:1 (0.01%) has-dict vocab-size:1 num-oods:9894 (98.9499%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0289864 min:-0.755433 max:0.964646 sd:0.141995\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 10000 example(s) and 1 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done rmse:0.143125\n",
            "[INFO random_forest.cc:578] Training of tree  14/30 (tree index:14) done rmse:0.142109\n",
            "[INFO random_forest.cc:578] Training of tree  24/30 (tree index:23) done rmse:0.14201\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:28) done rmse:0.14201\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:0.14201\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp0b6cx0wr\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 30 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019926436245441437 in 0.6002175807952881 secs\n",
            "157/157 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 157\n",
            "[INFO kernel.cc:393] Number of examples: 10000\n",
            "[INFO data_spec_inference.cc:289] 9894 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 10000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:1 (0.01%) has-dict vocab-size:1 num-oods:9894 (98.9499%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0289864 min:-0.755433 max:0.964646 sd:0.141995\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 10000 example(s) and 1 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:0.142006 train-rmse:0.142006 valid-loss:0.141905 valid-rmse:0.141905\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:0.142006 train-rmse:0.142006 valid-loss:0.141905 valid-rmse:0.141905\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 1 tree(s) i.e. 1  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:1 valid-loss:0.141905 valid-rmse:0.141905\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp4sr6w58a\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.01992684230208397 in 0.593928337097168 secs\n",
            "157/157 [==============================] - 0s 996us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 157\n",
            "[INFO kernel.cc:393] Number of examples: 10000\n",
            "[INFO data_spec_inference.cc:289] 9894 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 10000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:1 (0.01%) has-dict vocab-size:1 num-oods:9894 (98.9499%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0289864 min:-0.755433 max:0.964646 sd:0.141995\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 10000 example(s) and 1 feature(s).\n",
            "[INFO cart.cc:371] 1 nodes before pruning. 1 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpibckjuee\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[WARNING utils.cc:73] The model does not have any input features i.e. the model is constant and will always return the same prediction.\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1 node(s), and 0 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.01992684230208397 in 0.6619422435760498 secs\n",
            "30000 examples in training, 3239 examples for testing.\n",
            "469/469 [==============================] - 0s 954us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 469\n",
            "[INFO kernel.cc:393] Number of examples: 30000\n",
            "[INFO data_spec_inference.cc:289] 29092 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 30000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:5 (0.0166667%) has-dict vocab-size:5 num-oods:29092 (96.9895%) most-frequent:\"<OOD>\" 29092 (96.9895%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0279617 min:-0.755433 max:0.964646 sd:0.142968\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 30000 example(s) and 1 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:2) done rmse:0.144333\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:11) done rmse:0.142858\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done rmse:0.142947\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done rmse:0.142948\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:0.142948\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpxj91rp1f\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 188 node(s), and 1 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019919566810131073 in 1.6524064540863037 secs\n",
            "469/469 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 469\n",
            "[INFO kernel.cc:393] Number of examples: 30000\n",
            "[INFO data_spec_inference.cc:289] 29092 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 30000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:5 (0.0166667%) has-dict vocab-size:5 num-oods:29092 (96.9895%) most-frequent:\"<OOD>\" 29092 (96.9895%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0279617 min:-0.755433 max:0.964646 sd:0.142968\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 30000 example(s) and 1 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:0.142936 train-rmse:0.142936 valid-loss:0.143203 valid-rmse:0.143203\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:0.142911 train-rmse:0.142911 valid-loss:0.143191 valid-rmse:0.143191\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:29 valid-loss:0.143191 valid-rmse:0.143191\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpmh2br7bf\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO abstract_model.cc:993] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019918713718652725 in 1.61977219581604 secs\n",
            "469/469 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 469\n",
            "[INFO kernel.cc:393] Number of examples: 30000\n",
            "[INFO data_spec_inference.cc:289] 29092 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 30000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:5 (0.0166667%) has-dict vocab-size:5 num-oods:29092 (96.9895%) most-frequent:\"<OOD>\" 29092 (96.9895%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0279617 min:-0.755433 max:0.964646 sd:0.142968\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 30000 example(s) and 1 feature(s).\n",
            "[INFO cart.cc:371] 7 nodes before pruning. 7 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpvwfmc8dv\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 7 node(s), and 1 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019918719306588173 in 0.9971320629119873 secs\n",
            "50000 examples in training, 3239 examples for testing.\n",
            "782/782 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 782\n",
            "[INFO kernel.cc:393] Number of examples: 50000\n",
            "[INFO data_spec_inference.cc:289] 47676 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (27 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 50000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:9 (0.018%) has-dict vocab-size:28 num-oods:47676 (95.3692%) most-frequent:\"<OOD>\" 47676 (95.3692%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0273147 min:-0.755433 max:0.964646 sd:0.14269\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 50000 example(s) and 1 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:1) done rmse:0.142767\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:11) done rmse:0.142554\n",
            "[INFO random_forest.cc:578] Training of tree  22/30 (tree index:24) done rmse:0.142519\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done rmse:0.142526\n",
            "[INFO random_forest.cc:645] Final OOB metrics: rmse:0.142526\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpob42mh03\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 1178 node(s), and 1 input feature(s).\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019902149215340614 in 2.9028003215789795 secs\n",
            "782/782 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 782\n",
            "[INFO kernel.cc:393] Number of examples: 50000\n",
            "[INFO data_spec_inference.cc:289] 47676 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (27 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 50000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:9 (0.018%) has-dict vocab-size:28 num-oods:47676 (95.3692%) most-frequent:\"<OOD>\" 47676 (95.3692%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0273147 min:-0.755433 max:0.964646 sd:0.14269\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1692] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1705] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1714] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1726] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:503] Default loss set to SQUARED_ERROR\n",
            "[INFO gradient_boosted_trees.cc:1079] Training gradient boosted tree on 50000 example(s) and 1 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:1 train-loss:0.142760 train-rmse:0.142760 valid-loss:0.141741 valid-rmse:0.141741\n",
            "[INFO gradient_boosted_trees.cc:1493] \tnum-trees:30 train-loss:0.142624 train-rmse:0.142624 valid-loss:0.141599 valid-rmse:0.141599\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 30 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.141599 valid-rmse:0.141599\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp3xpko6ml\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:988] Loading model from path\n",
            "[INFO kernel.cc:848] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - mse: 0.0199\n",
            "MSE: 0.019902309402823448 in 2.920426845550537 secs\n",
            "782/782 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 782\n",
            "[INFO kernel.cc:393] Number of examples: 50000\n",
            "[INFO data_spec_inference.cc:289] 47676 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Headline (27 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 50000\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\tNUMERICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t0: \"Headline\" CATEGORICAL num-nas:9 (0.018%) has-dict vocab-size:28 num-oods:47676 (95.3692%) most-frequent:\"<OOD>\" 47676 (95.3692%)\n",
            "\n",
            "NUMERICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" NUMERICAL mean:-0.0273147 min:-0.755433 max:0.964646 sd:0.14269\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"Headline\"\n",
            "label: \"__LABEL\"\n",
            "task: REGRESSION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "num_threads: 6\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 50000 example(s) and 1 feature(s).\n",
            "[INFO cart.cc:371] 39 nodes before pruning. 15 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpin11v84q\n",
            "[INFO kernel.cc:864] Save model in resources\n",