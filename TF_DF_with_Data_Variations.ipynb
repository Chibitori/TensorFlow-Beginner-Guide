{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF DF with Data Variations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjX8UBXpAREUqbqc9fNn0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikmswamy/TF_Intro_Notebooks/blob/master/TF_DF_with_Data_Variations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xrI9mMFGAK"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u1n95o8f1Sz"
      },
      "source": [
        "# !pip install -U augly\n",
        "# !sudo apt-get install python3-magic\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZjEjvCeFJtI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWIfTG5Mgok3"
      },
      "source": [
        "from time import time\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av22s03cFNMg"
      },
      "source": [
        "## Data Download and Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "ORMNK-GRvs1N",
        "outputId": "0ed081be-ae25-42a7-f42b-e05ca30b4893"
      },
      "source": [
        "! wget -O bestBuy.csv \"https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\"\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"./bestBuy.csv\", usecols=['manufacturer', 'price', 'level1_category'])\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-20 13:30:43--  https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9921374 (9.5M) [text/plain]\n",
            "Saving to: ‘bestBuy.csv’\n",
            "\n",
            "bestBuy.csv         100%[===================>]   9.46M  35.0MB/s    in 0.3s    \n",
            "\n",
            "2021-07-20 13:30:43 (35.0 MB/s) - ‘bestBuy.csv’ saved [9921374/9921374]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>price</th>\n",
              "      <th>level1_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>7.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  manufacturer  price              level1_category\n",
              "0     Duracell   5.49  Connected Home & Housewares\n",
              "1     Duracell   5.49  Connected Home & Housewares\n",
              "2     Duracell   7.49  Connected Home & Housewares"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBkfGBICQlA",
        "outputId": "e4ced1ad-66e8-4284-e4f7-871dce18b5a2"
      },
      "source": [
        "dataset_df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48087 entries, 0 to 48086\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   manufacturer     48023 non-null  object \n",
            " 1   price            48087 non-null  float64\n",
            " 2   level1_category  47906 non-null  object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AckVwakyK2w",
        "outputId": "8152b6b5-aef7-4db7-e3b1-56ce8beae776"
      },
      "source": [
        "# Name of the label column.\n",
        "label = \"level1_category\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label classes: ['Connected Home & Housewares', nan, 'Car Electronics & GPS', 'Musical Instruments', 'Toys, Games & Drones', 'Video Games', 'Cameras & Camcorders', 'Computers & Tablets', 'Appliances', 'Audio', 'TV & Home Theater', 'Health, Fitness & Beauty', 'Name Brands', 'Cell Phones', 'Movies & Music', 'Magnolia Home Theater', 'Geek Squad', 'Best Buy Gift Cards', 'Wearable Technology', 'Gift Ideas', 'Housewares']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csVpYLqVFSbI"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0guQ8ZfPyUGp"
      },
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "# Test split remains a constant \n",
        "def split_dataset(dataset, num_train=10000):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  dataset = dataset.sample(frac=1.0, random_state=1729)\n",
        "  \n",
        "  test_dataset = dataset[40000:]\n",
        "  train_dataset = dataset[:num_train]\n",
        "  \n",
        "  return train_dataset, test_dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhY2Dcoopv6V"
      },
      "source": [
        "def train_rf_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.RandomForestModel(num_trees=30)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KWdeFTmwXlu"
      },
      "source": [
        "def train_gbdt_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.GradientBoostedTreesModel(num_trees=30)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPDKs0dWMEKU"
      },
      "source": [
        "def train_cart_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.CartModel()\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQjlNHKFayw"
      },
      "source": [
        "## Train with Different Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiNb6QjF30m"
      },
      "source": [
        "def train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm):\n",
        "    train_ds_pd, test_ds_pd = split_dataset(dataset_df, num_train)\n",
        "    print(f\"{len(train_ds_pd)} examples in training, {len(test_ds_pd)} examples for testing.\")\n",
        "\n",
        "    accuracy, time_taken = train_rf_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_rf.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_gbdt_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_gb.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_cart_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_cm.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    return results_rf, results_gb, results_cm"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSg1c2rUWv2_",
        "outputId": "54a7c642-2ef2-49f7-ff26-9c3f55bceb62"
      },
      "source": [
        "results_rf, results_gb, results_cm = [], [], []\n",
        "num_train_list = [500, 1000, 2000, 4000, 8000, 16000, 32000, 40000]\n",
        "for num_train in num_train_list:\n",
        "    results_rf, results_gb, results_cm = train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 examples in training, 8087 examples for testing.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-20 13:30:49.287148: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-07-20 13:30:49.290940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 5s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 500 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done accuracy:0.263736 logloss:26.5376\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:13) done accuracy:0.280242 logloss:21.9009\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:18) done accuracy:0.270541 logloss:18.4027\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.288 logloss:16.6408\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.288 logloss:16.6408\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpg9lbypms\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 2926 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2808\n",
            "Accuracy: 0.2808210849761963 in 8.342710018157959 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disa