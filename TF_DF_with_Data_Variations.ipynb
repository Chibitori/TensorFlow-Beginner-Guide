{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF DF with Data Variations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjX8UBXpAREUqbqc9fNn0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikmswamy/TF_Intro_Notebooks/blob/master/TF_DF_with_Data_Variations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xrI9mMFGAK"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u1n95o8f1Sz"
      },
      "source": [
        "# !pip install -U augly\n",
        "# !sudo apt-get install python3-magic\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZjEjvCeFJtI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWIfTG5Mgok3"
      },
      "source": [
        "from time import time\n",
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "try:\n",
        "  from wurlitzer import sys_pipes\n",
        "except:\n",
        "  from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "\n",
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av22s03cFNMg"
      },
      "source": [
        "## Data Download and Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "ORMNK-GRvs1N",
        "outputId": "0ed081be-ae25-42a7-f42b-e05ca30b4893"
      },
      "source": [
        "! wget -O bestBuy.csv \"https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\"\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"./bestBuy.csv\", usecols=['manufacturer', 'price', 'level1_category'])\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-20 13:30:43--  https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9921374 (9.5M) [text/plain]\n",
            "Saving to: ‘bestBuy.csv’\n",
            "\n",
            "bestBuy.csv         100%[===================>]   9.46M  35.0MB/s    in 0.3s    \n",
            "\n",
            "2021-07-20 13:30:43 (35.0 MB/s) - ‘bestBuy.csv’ saved [9921374/9921374]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>price</th>\n",
              "      <th>level1_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>5.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Duracell</td>\n",
              "      <td>7.49</td>\n",
              "      <td>Connected Home &amp; Housewares</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  manufacturer  price              level1_category\n",
              "0     Duracell   5.49  Connected Home & Housewares\n",
              "1     Duracell   5.49  Connected Home & Housewares\n",
              "2     Duracell   7.49  Connected Home & Housewares"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueBkfGBICQlA",
        "outputId": "e4ced1ad-66e8-4284-e4f7-871dce18b5a2"
      },
      "source": [
        "dataset_df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48087 entries, 0 to 48086\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   manufacturer     48023 non-null  object \n",
            " 1   price            48087 non-null  float64\n",
            " 2   level1_category  47906 non-null  object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AckVwakyK2w",
        "outputId": "8152b6b5-aef7-4db7-e3b1-56ce8beae776"
      },
      "source": [
        "# Name of the label column.\n",
        "label = \"level1_category\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label classes: ['Connected Home & Housewares', nan, 'Car Electronics & GPS', 'Musical Instruments', 'Toys, Games & Drones', 'Video Games', 'Cameras & Camcorders', 'Computers & Tablets', 'Appliances', 'Audio', 'TV & Home Theater', 'Health, Fitness & Beauty', 'Name Brands', 'Cell Phones', 'Movies & Music', 'Magnolia Home Theater', 'Geek Squad', 'Best Buy Gift Cards', 'Wearable Technology', 'Gift Ideas', 'Housewares']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csVpYLqVFSbI"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0guQ8ZfPyUGp"
      },
      "source": [
        "# Split the dataset into a training and a testing dataset.\n",
        "# Test split remains a constant \n",
        "def split_dataset(dataset, num_train=10000):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  dataset = dataset.sample(frac=1.0, random_state=1729)\n",
        "  \n",
        "  test_dataset = dataset[40000:]\n",
        "  train_dataset = dataset[:num_train]\n",
        "  \n",
        "  return train_dataset, test_dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhY2Dcoopv6V"
      },
      "source": [
        "def train_rf_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.RandomForestModel(num_trees=30)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KWdeFTmwXlu"
      },
      "source": [
        "def train_gbdt_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.GradientBoostedTreesModel(num_trees=30)\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPDKs0dWMEKU"
      },
      "source": [
        "def train_cart_model_with_dataframes(train_df, test_df, label):\n",
        "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=label)\n",
        "    test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=label)\n",
        "\n",
        "    # Specify the model.\n",
        "    model_1 = tfdf.keras.CartModel()\n",
        "\n",
        "    # Optionally, add evaluation metrics.\n",
        "    model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "    t1 = time()\n",
        "    # Train the model.\n",
        "    with sys_pipes():\n",
        "        model_1.fit(x=train_ds)\n",
        "\n",
        "    evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "    # print(f\"Loss: {evaluation[0]}\")\n",
        "    print(f\"Accuracy: {evaluation[1]} in {time() - t1} secs\")\n",
        "    return evaluation[1], time() - t1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQjlNHKFayw"
      },
      "source": [
        "## Train with Different Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiNb6QjF30m"
      },
      "source": [
        "def train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm):\n",
        "    train_ds_pd, test_ds_pd = split_dataset(dataset_df, num_train)\n",
        "    print(f\"{len(train_ds_pd)} examples in training, {len(test_ds_pd)} examples for testing.\")\n",
        "\n",
        "    accuracy, time_taken = train_rf_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_rf.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_gbdt_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_gb.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    accuracy, time_taken = train_cart_model_with_dataframes(train_ds_pd, test_ds_pd, label)\n",
        "    results_cm.append([num_train, accuracy, time_taken])\n",
        "\n",
        "    return results_rf, results_gb, results_cm"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSg1c2rUWv2_",
        "outputId": "54a7c642-2ef2-49f7-ff26-9c3f55bceb62"
      },
      "source": [
        "results_rf, results_gb, results_cm = [], [], []\n",
        "num_train_list = [500, 1000, 2000, 4000, 8000, 16000, 32000, 40000]\n",
        "for num_train in num_train_list:\n",
        "    results_rf, results_gb, results_cm = train_and_evaluate_on_data(num_train, results_rf, results_gb, results_cm)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 examples in training, 8087 examples for testing.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-20 13:30:49.287148: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-07-20 13:30:49.290940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 5s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 500 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done accuracy:0.263736 logloss:26.5376\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:13) done accuracy:0.280242 logloss:21.9009\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:18) done accuracy:0.270541 logloss:18.4027\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.288 logloss:16.6408\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.288 logloss:16.6408\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpg9lbypms\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 2926 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2808\n",
            "Accuracy: 0.2808210849761963 in 8.342710018157959 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 500 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.504685 train-accuracy:0.429515 valid-loss:2.532742 valid-accuracy:0.391304\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.319265 train-accuracy:0.436123 valid-loss:2.386813 valid-accuracy:0.456522\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.97548\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 380 tree(s) i.e. 20  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:20 valid-loss:1.975476 valid-accuracy:0.391304\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpmmgidanu\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 380 root(s), 11376 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3152\n",
            "Accuracy: 0.315197229385376 in 1.3797359466552734 secs\n",
            "8/8 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 8\n",
            "[INFO kernel.cc:393] Number of examples: 500\n",
            "[INFO data_spec_inference.cc:289] 287 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (15 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 500\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.2%) has-dict vocab-size:16 num-oods:287 (57.515%) most-frequent:\"<OOD>\" 287 (57.515%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.683 min:1.49 max:12300 sd:711.486\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 500 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 101 nodes before pruning. 3 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpbh6p4tey\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 3 node(s), and 1 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2383\n",
            "Accuracy: 0.2382836639881134 in 0.6427614688873291 secs\n",
            "1000 examples in training, 8087 examples for testing.\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 1000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:2) done accuracy:0.324251 logloss:24.3565\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:9) done accuracy:0.341734 logloss:18.6754\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done accuracy:0.347 logloss:15.7316\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.356 logloss:14.1981\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.356 logloss:14.1981\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp062b9hhj\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 4966 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3773\n",
            "Accuracy: 0.3772721588611603 in 0.8515772819519043 secs\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 1000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.430901 train-accuracy:0.460455 valid-loss:2.428566 valid-accuracy:0.350649\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.75173\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 532 tree(s) i.e. 28  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:28 valid-loss:1.751727 valid-accuracy:0.415584\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpfg1c2sag\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 532 root(s), 19408 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c7e9dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c7e9dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 0.3874\n",
            "Accuracy: 0.387411892414093 in 1.8938877582550049 secs\n",
            "16/16 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 16\n",
            "[INFO kernel.cc:393] Number of examples: 1000\n",
            "[INFO data_spec_inference.cc:289] 449 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (36 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 1000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:1 (0.1%) has-dict vocab-size:37 num-oods:449 (44.9449%) most-frequent:\"<OOD>\" 449 (44.9449%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:262.11 min:1.49 max:12300 sd:660.015\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 1000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 167 nodes before pruning. 43 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp5c989ik5\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 43 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c967200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f209c967200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3054\n",
            "Accuracy: 0.30542847514152527 in 0.6774287223815918 secs\n",
            "2000 examples in training, 8087 examples for testing.\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 2000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:3) done accuracy:0.404632 logloss:21.4592\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:8) done accuracy:0.479859 logloss:14.7911\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:21) done accuracy:0.488 logloss:12.2939\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.4925 logloss:11.1767\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.4925 logloss:11.1767\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp1i_a492q\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 8334 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.4635\n",
            "Accuracy: 0.46345987915992737 in 1.7955348491668701 secs\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 2000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.292626 train-accuracy:0.531798 valid-loss:2.383888 valid-accuracy:0.460227\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.52684\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 513 tree(s) i.e. 27  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:27 valid-loss:1.526842 valid-accuracy:0.505682\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpcc7t83a3\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 513 root(s), 21385 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 0.4757\n",
            "Accuracy: 0.4757017493247986 in 2.2559468746185303 secs\n",
            "32/32 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 32\n",
            "[INFO kernel.cc:393] Number of examples: 2000\n",
            "[INFO data_spec_inference.cc:289] 614 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (88 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 2000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:3 (0.15%) has-dict vocab-size:89 num-oods:614 (30.7461%) most-frequent:\"<OOD>\" 614 (30.7461%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.659 min:0.01 max:12300 sd:640.932\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 2000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 287 nodes before pruning. 77 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp2ftcoeae\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 77 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.4513\n",
            "Accuracy: 0.4513416588306427 in 0.7589678764343262 secs\n",
            "4000 examples in training, 8087 examples for testing.\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 4000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:2) done accuracy:0.600962 logloss:14.3828\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done accuracy:0.606091 logloss:10.7036\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:18) done accuracy:0.61625 logloss:8.95603\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.618 logloss:8.16299\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.618 logloss:8.16299\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpb0bzyd_l\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 14888 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5918\n",
            "Accuracy: 0.5918140411376953 in 2.4782557487487793 secs\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 4000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.058783 train-accuracy:0.648425 valid-loss:2.124822 valid-accuracy:0.599476\n",
            "[INFO gradient_boosted_trees.cc:2746] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.14679\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 532 tree(s) i.e. 28  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:28 valid-loss:1.146789 valid-accuracy:0.615183\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpgwls29bs\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 532 root(s), 24166 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 0.5995\n",
            "Accuracy: 0.5994806289672852 in 3.07039213180542 secs\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 63\n",
            "[INFO kernel.cc:393] Number of examples: 4000\n",
            "[INFO data_spec_inference.cc:289] 759 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (212 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 4000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:5 (0.125%) has-dict vocab-size:213 num-oods:759 (18.9987%) most-frequent:\"<OOD>\" 759 (18.9987%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:260.872 min:0.01 max:12300 sd:631.2\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 4000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 497 nodes before pruning. 119 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp51i7vnlt\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 119 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.5731\n",
            "Accuracy: 0.5731420516967773 in 0.8729896545410156 secs\n",
            "8000 examples in training, 8087 examples for testing.\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 8000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:4) done accuracy:0.633803 logloss:13.1991\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done accuracy:0.659781 logloss:8.66796\n",
            "[INFO random_forest.cc:578] Training of tree  21/30 (tree index:20) done accuracy:0.681375 logloss:7.00761\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.69225 logloss:6.26266\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.69225 logloss:6.26266\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpr02z3u9l\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 36334 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6872\n",
            "Accuracy: 0.6871522068977356 in 23.577579259872437 secs\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 8000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.420986 train-accuracy:0.519823 valid-loss:2.477244 valid-accuracy:0.449109\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.110891 train-accuracy:0.606737 valid-loss:2.192795 valid-accuracy:0.557252\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:9 train-loss:1.313544 train-accuracy:0.718464 valid-loss:1.471560 valid-accuracy:0.646310\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:16 train-loss:1.006907 train-accuracy:0.751178 valid-loss:1.198588 valid-accuracy:0.687023\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:23 train-loss:0.850335 train-accuracy:0.763654 valid-loss:1.066212 valid-accuracy:0.685751\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.758309 train-accuracy:0.773773 valid-loss:0.997799 valid-accuracy:0.697201\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 570 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.997799 valid-accuracy:0.697201\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpwfi9iyx4\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 570 root(s), 32860 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 0.6937\n",
            "Accuracy: 0.6937059760093689 in 131.69450116157532 secs\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 125\n",
            "[INFO kernel.cc:393] Number of examples: 8000\n",
            "[INFO data_spec_inference.cc:289] 906 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (381 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 8000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:8 (0.1%) has-dict vocab-size:382 num-oods:906 (11.3363%) most-frequent:\"<OOD>\" 906 (11.3363%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:20 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:256.176 min:0.01 max:12300 sd:586.041\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 8000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 1235 nodes before pruning. 391 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmphk_3knjh\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 391 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6115\n",
            "Accuracy: 0.6114752292633057 in 1.8574111461639404 secs\n",
            "16000 examples in training, 8087 examples for testing.\n",
            "250/250 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 16000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:1) done accuracy:0.692846 logloss:11.0709\n",
            "[INFO random_forest.cc:578] Training of tree  11/30 (tree index:10) done accuracy:0.725454 logloss:6.67471\n",
            "[INFO random_forest.cc:578] Training of tree  19/30 (tree index:18) done accuracy:0.749563 logloss:5.46844\n",
            "[INFO random_forest.cc:578] Training of tree  28/30 (tree index:27) done accuracy:0.7575 logloss:4.81412\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.759313 logloss:4.72709\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.759313 logloss:4.72709\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpz1t1_ix4\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 67100 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.7564\n",
            "Accuracy: 0.7563991546630859 in 82.80359506607056 secs\n",
            "250/250 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 16000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.467717 train-accuracy:0.502079 valid-loss:2.483016 valid-accuracy:0.488535\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.201852 train-accuracy:0.578517 valid-loss:2.231717 valid-accuracy:0.557325\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:6 train-loss:1.590960 train-accuracy:0.686417 valid-loss:1.660925 valid-accuracy:0.659236\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:10 train-loss:1.267854 train-accuracy:0.735204 valid-loss:1.360176 valid-accuracy:0.697452\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:14 train-loss:1.072730 train-accuracy:0.764033 valid-loss:1.182369 valid-accuracy:0.716560\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:18 train-loss:0.935425 train-accuracy:0.783299 valid-loss:1.058977 valid-accuracy:0.731847\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:22 train-loss:0.843958 train-accuracy:0.794248 valid-loss:0.980143 valid-accuracy:0.748408\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:26 train-loss:0.774142 train-accuracy:0.802010 valid-loss:0.918219 valid-accuracy:0.759873\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.717929 train-accuracy:0.808177 valid-loss:0.873268 valid-accuracy:0.761146\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 600 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.873268 valid-accuracy:0.761146\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpzvs716wq\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 600 root(s), 35322 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.7581\n",
            "Accuracy: 0.7581303119659424 in 263.0507712364197 secs\n",
            "250/250 [==============================] - 0s 953us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 250\n",
            "[INFO kernel.cc:393] Number of examples: 16000\n",
            "[INFO data_spec_inference.cc:289] 1024 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (626 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 16000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:18 (0.1125%) has-dict vocab-size:627 num-oods:1024 (6.40721%) most-frequent:\"<OOD>\" 1024 (6.40721%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.794 min:0.01 max:18000 sd:590.45\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 16000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 2263 nodes before pruning. 675 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmphbw_fx5h\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 675 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6724\n",
            "Accuracy: 0.6724372506141663 in 2.787523031234741 secs\n",
            "32000 examples in training, 8087 examples for testing.\n",
            "500/500 [==============================] - 1s 999us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 32000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:4) done accuracy:0.764318 logloss:8.49483\n",
            "[INFO random_forest.cc:578] Training of tree  7/30 (tree index:10) done accuracy:0.777803 logloss:6.06134\n",
            "[INFO random_forest.cc:578] Training of tree  13/30 (tree index:13) done accuracy:0.797462 logloss:4.78001\n",
            "[INFO random_forest.cc:578] Training of tree  19/30 (tree index:18) done accuracy:0.807171 logloss:4.1572\n",
            "[INFO random_forest.cc:578] Training of tree  25/30 (tree index:24) done accuracy:0.811113 logloss:3.80479\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.813994 logloss:3.5884\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.813994 logloss:3.5884\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpvepa8cjh\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 112638 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.8149\n",
            "Accuracy: 0.8148881196975708 in 82.7915563583374 secs\n",
            "500/500 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 32000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.441828 train-accuracy:0.516566 valid-loss:2.453953 valid-accuracy:0.502362\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.211591 train-accuracy:0.578317 valid-loss:2.230616 valid-accuracy:0.544882\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:5 train-loss:1.729643 train-accuracy:0.666297 valid-loss:1.772863 valid-accuracy:0.635591\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:8 train-loss:1.438660 train-accuracy:0.708517 valid-loss:1.496117 valid-accuracy:0.674016\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:11 train-loss:1.238807 train-accuracy:0.737693 valid-loss:1.307113 valid-accuracy:0.697008\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:14 train-loss:1.088870 train-accuracy:0.763053 valid-loss:1.165866 valid-accuracy:0.727559\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:17 train-loss:0.987956 train-accuracy:0.777381 valid-loss:1.071286 valid-accuracy:0.742992\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:20 train-loss:0.904093 train-accuracy:0.791327 valid-loss:0.993378 valid-accuracy:0.757795\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:23 train-loss:0.836633 train-accuracy:0.803677 valid-loss:0.929567 valid-accuracy:0.765669\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:26 train-loss:0.783156 train-accuracy:0.811830 valid-loss:0.881306 valid-accuracy:0.773543\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:29 train-loss:0.736151 train-accuracy:0.819566 valid-loss:0.838564 valid-accuracy:0.782992\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.722443 train-accuracy:0.821752 valid-loss:0.826466 valid-accuracy:0.782992\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 600 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.826466 valid-accuracy:0.782992\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpz_qye8mt\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 600 root(s), 35946 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.7893\n",
            "Accuracy: 0.7892914414405823 in 370.16597843170166 secs\n",
            "500/500 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 500\n",
            "[INFO kernel.cc:393] Number of examples: 32000\n",
            "[INFO data_spec_inference.cc:289] 1144 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (931 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 32000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:44 (0.1375%) has-dict vocab-size:932 num-oods:1144 (3.57992%) most-frequent:\"<OOD>\" 1144 (3.57992%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:21 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:253.956 min:0.01 max:18000 sd:575.973\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 32000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 3871 nodes before pruning. 1225 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmprvjzlvtp\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1225 node(s), and 2 input feature(s).\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.7515\n",
            "Accuracy: 0.7514529228210449 in 5.532477140426636 secs\n",
            "40000 examples in training, 8087 examples for testing.\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:22 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO random_forest.cc:303] Training random forest on 40000 example(s) and 2 feature(s).\n",
            "[INFO random_forest.cc:578] Training of tree  1/30 (tree index:0) done accuracy:0.778377 logloss:7.98809\n",
            "[INFO random_forest.cc:578] Training of tree  7/30 (tree index:6) done accuracy:0.794312 logloss:5.52983\n",
            "[INFO random_forest.cc:578] Training of tree  13/30 (tree index:13) done accuracy:0.812481 logloss:4.32219\n",
            "[INFO random_forest.cc:578] Training of tree  19/30 (tree index:19) done accuracy:0.822135 logloss:3.7724\n",
            "[INFO random_forest.cc:578] Training of tree  25/30 (tree index:24) done accuracy:0.826721 logloss:3.44836\n",
            "[INFO random_forest.cc:578] Training of tree  30/30 (tree index:29) done accuracy:0.828875 logloss:3.23323\n",
            "[INFO random_forest.cc:645] Final OOB metrics: accuracy:0.828875 logloss:3.23323\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmp946ibqun\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 30 root(s), 131136 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.8313\n",
            "Accuracy: 0.8313342332839966 in 142.542662858963 secs\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:22 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[WARNING gradient_boosted_trees.cc:1688] Subsample hyperparameter given but sampling method does not match.\n",
            "[WARNING gradient_boosted_trees.cc:1701] GOSS alpha hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1710] GOSS beta hyperparameter given but GOSS is disabled.\n",
            "[WARNING gradient_boosted_trees.cc:1722] SelGB ratio hyperparameter given but SelGB is disabled.\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 6\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  validation_set_ratio: 0.1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  apply_link_function: true\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO gradient_boosted_trees.cc:499] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[INFO gradient_boosted_trees.cc:1075] Training gradient boosted tree on 40000 example(s) and 2 feature(s).\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:1 train-loss:2.458010 train-accuracy:0.529781 valid-loss:2.459713 valid-accuracy:0.509572\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:2 train-loss:2.190670 train-accuracy:0.593922 valid-loss:2.201176 valid-accuracy:0.574559\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:5 train-loss:1.709499 train-accuracy:0.675687 valid-loss:1.730257 valid-accuracy:0.653904\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:8 train-loss:1.420376 train-accuracy:0.718540 valid-loss:1.452650 valid-accuracy:0.697229\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:11 train-loss:1.222638 train-accuracy:0.745379 valid-loss:1.263874 valid-accuracy:0.725693\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:14 train-loss:1.075657 train-accuracy:0.768498 valid-loss:1.127880 valid-accuracy:0.744081\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:17 train-loss:0.970285 train-accuracy:0.785235 valid-loss:1.029183 valid-accuracy:0.762469\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:20 train-loss:0.888751 train-accuracy:0.798834 valid-loss:0.954554 valid-accuracy:0.772544\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:23 train-loss:0.821590 train-accuracy:0.808770 valid-loss:0.891976 valid-accuracy:0.781864\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:26 train-loss:0.768245 train-accuracy:0.817374 valid-loss:0.842659 valid-accuracy:0.790428\n",
            "[INFO gradient_boosted_trees.cc:1491] \tnum-trees:29 train-loss:0.722492 train-accuracy:0.824757 valid-loss:0.800832 valid-accuracy:0.798237\n",
            "[INFO gradient_boosted_trees.cc:1489] \tnum-trees:30 train-loss:0.708173 train-accuracy:0.827089 valid-loss:0.787731 valid-accuracy:0.800504\n",
            "[INFO gradient_boosted_trees.cc:336] Truncates the model to 630 tree(s) i.e. 30  iteration(s).\n",
            "[INFO gradient_boosted_trees.cc:370] Final model num-trees:30 valid-loss:0.787731 valid-accuracy:0.800504\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpkr0webmn\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 630 root(s), 37648 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"GradientBoostedTreesGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.8002\n",
            "Accuracy: 0.8001731038093567 in 443.1349506378174 secs\n",
            "625/625 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO kernel.cc:746] Start Yggdrasil model training\n",
            "[INFO kernel.cc:747] Collect training examples\n",
            "[INFO kernel.cc:392] Number of batches: 625\n",
            "[INFO kernel.cc:393] Number of examples: 40000\n",
            "[INFO data_spec_inference.cc:289] 1153 item(s) have been pruned (i.e. they are considered out of dictionary) for the column manufacturer (1045 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "[INFO kernel.cc:769] Dataset:\n",
            "Number of records: 40000\n",
            "Number of columns: 3\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL: 2 (66.6667%)\n",
            "\tNUMERICAL: 1 (33.3333%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL: 2 (66.6667%)\n",
            "\t0: \"manufacturer\" CATEGORICAL num-nas:52 (0.13%) has-dict vocab-size:1046 num-oods:1153 (2.88625%) most-frequent:\"<OOD>\" 1153 (2.88625%)\n",
            "\t2: \"__LABEL\" CATEGORICAL integerized vocab-size:22 no-ood-item\n",
            "\n",
            "NUMERICAL: 1 (33.3333%)\n",
            "\t1: \"price\" NUMERICAL mean:255.547 min:0.01 max:28000 sd:588.007\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO kernel.cc:772] Configure learner\n",
            "[INFO kernel.cc:797] Training config:\n",
            "learner: \"CART\"\n",
            "features: \"manufacturer\"\n",
            "features: \"price\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.cart.proto.cart_config] {\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "  }\n",
            "  validation_ratio: 0.1\n",
            "}\n",
            "\n",
            "[INFO kernel.cc:800] Deployment config:\n",
            "\n",
            "[INFO kernel.cc:837] Train model\n",
            "[INFO cart.cc:172] Training CART on 40000 example(s) and 2 feature(s).\n",
            "[INFO cart.cc:366] 4501 nodes before pruning. 1535 nodes after pruning.\n",
            "[INFO kernel.cc:856] Export model in log directory: /tmp/tmpa32s8evq\n",
            "[INFO kernel.cc:864] Save model in resources\n",
            "[INFO kernel.cc:960] Loading model from path\n",
            "[INFO decision_forest.cc:590] Model loaded with 1 root(s), 1535 node(s), and 2 input feature(s).\n",
            "[INFO abstract_model.cc:973] Engine \"RandomForestGeneric\" built\n",
            "[INFO kernel.cc:820] Use fast generic engine\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.7667\n",
            "Accuracy: 0.7666625380516052 in 4.98656702041626 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-XEOe1vFn6Z"
      },
      "source": [
        "## Plotting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "I6e-QbOzI1oN",
        "outputId": "ad846a9e-be97-435c-dce4-92e437b259d5"
      },
      "source": [
        "x  = [res[0] for res in results_rf]\n",
        "y1 = [res[1] for res in results_rf]\n",
        "y2 = [res[1] for res in results_gb]\n",
        "y3 = [res[1] for res in results_cm]\n",
        "plt.plot(x, y1, label=\"Random Forests\", marker='^')\n",
        "plt.plot(x, y2, label=\"Gradient Boosting\", marker='o')\n",
        "plt.plot(x, y3, label=\"CART\", marker='o')\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Number of Records\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Plot of # of Records vs. Accuracies\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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